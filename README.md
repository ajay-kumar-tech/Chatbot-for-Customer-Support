# Chatbot-for-Customer-Support
This project develops a Customer Support Chatbot using a Transformer-based Seq2Seq model with Encoder, Decoder, and Attention Mechanism. Instead of training from scratch, it fine-tunes a pre-trained model (GPT-2, BERT, or T5) using transfer learning for better performance, ensuring accurate, context-aware, and human-like responses
